{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gqErFY_lLQnE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n2GSYjBZLvqW"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "# !pip install transformers torch pandas scikit-learn\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('updated_final.csv')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY0QN7YdMK_f",
    "outputId": "46a52787-9bc8-469d-b2d2-5a78bd68d392"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\heyfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\heyfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\heyfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters, keeping apostrophes for contractions\n",
    "    text = re.sub(r'[^a-zA-Z\\'\\s]', ' ', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Custom list of stopwords, excluding negations and other sentiment-bearing words\n",
    "    custom_stop_words = set([\n",
    "        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'\n",
    "    ])\n",
    "\n",
    "    # List of negations and sentiment-bearing words to keep\n",
    "    important_words = set([\n",
    "        'not', 'no', 'never', 'none', 'nobody', 'nowhere', 'neither', 'nor',\n",
    "        'doesn\\'t', 'isn\\'t', 'wasn\\'t', 'shouldn\\'t', 'wouldn\\'t', 'couldn\\'t', 'won\\'t',\n",
    "        'can\\'t', 'don\\'t'\n",
    "    ])\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove custom stopwords but keep important words\n",
    "    tokens = [token for token in tokens if token not in stop_words or token in important_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jAJeMb7qMP1A"
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to the 'text' column\n",
    "df['text']=df['text'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S_eq3euBMJHF"
   },
   "outputs": [],
   "source": [
    "# Encode labels and aspects\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "aspect_encoder = LabelEncoder()\n",
    "df['span_encoded'] = aspect_encoder.fit_transform(df['span'])\n",
    "\n",
    "# Split the data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0UVVf4bCNyj9"
   },
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class AspectSentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.iloc[index]['text']\n",
    "        aspect = self.data.iloc[index]['span']\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            aspect,\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs['token_type_ids'].flatten(),\n",
    "            'labels': torch.tensor(self.data.iloc[index]['label_encoded'], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_1_GNk_N2F_",
    "outputId": "c1dd4532-fd20-4392-812f-7fbf18141ab0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WCrxLo3sN5Tk"
   },
   "outputs": [],
   "source": [
    "# Prepare datasets and dataloaders\n",
    "train_dataset = AspectSentimentDataset(train_df, tokenizer, max_len=128)\n",
    "val_dataset = AspectSentimentDataset(val_df, tokenizer, max_len=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7C7tnQgN-oV",
    "outputId": "5c8e8289-63b7-4e0e-f976-95b2eeb60e86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DvbzEo0sPZa8"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYfTeH8UOBxc",
    "outputId": "c3eb519c-1e24-4bfe-af85-3529f97b044a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:16<?, ?it/s, loss=0]\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.382, accuracy=81.2]\u001b[A\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.643, accuracy=84.4]\u001b[A\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.896, accuracy=87.5]\u001b[A\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=1.26, accuracy=87.5] \u001b[A\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=1.83, accuracy=85]  \u001b[A\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=2.26, accuracy=84.4]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=2.5, accuracy=85.7] \u001b[A\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=2.84, accuracy=85.9]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=3.09, accuracy=86.8]\u001b[A\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=3.49, accuracy=86.6]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6, Validation Accuracy: 86.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/6 [Train]:   0%|          | 0/40 [00:17<?, ?it/s, loss=0]\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:14<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 1/6 [Validation]:   0%|          | 0/10 [00:15<?, ?it/s, loss=3.49, accuracy=86.6]\n",
      "Epoch 2/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.79, accuracy=96.9]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 2/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=1.15, accuracy=96.1] Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 2/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=1.36, accuracy=96.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6, Validation Accuracy: 96.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 2/6 [Train]:   0%|          | 0/40 [00:15<?, ?it/s, loss=0]\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\u001b[A\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 2/6 [Validation]:   0%|          | 0/10 [00:14<?, ?it/s, loss=1.36, accuracy=96.8]\n",
      "\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.131, accuracy=96.9] \u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.153, accuracy=97.9]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.192, accuracy=98.4]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.248, accuracy=98.8]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.328, accuracy=99]  \u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.356, accuracy=99.1]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.808, accuracy=96.9]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.83, accuracy=97.2] \u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.925, accuracy=96.8]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6, Validation Accuracy: 96.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/6 [Train]:   0%|          | 0/40 [00:14<?, ?it/s, loss=0]\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\n",
      "Epoch 3/6 [Validation]:   0%|          | 0/10 [00:14<?, ?it/s, loss=0.925, accuracy=96.8]\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0235, accuracy=100]\u001b[A\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0378, accuracy=100]\u001b[A\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0473, accuracy=100]\u001b[A\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0596, accuracy=100]\u001b[A\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0794, accuracy=100]\u001b[A\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.108, accuracy=100] \u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.121, accuracy=100]\u001b[A\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.661, accuracy=97.7]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.67, accuracy=97.9] \u001b[A\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.72, accuracy=98.1]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6, Validation Accuracy: 98.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Train]:   0%|          | 0/40 [00:14<?, ?it/s, loss=0]\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 4/6 [Validation]:   0%|          | 0/10 [00:14<?, ?it/s, loss=0.72, accuracy=98.1]\n",
      "Epoch 5/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.636, accuracy=97.9]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 5/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=1.68, accuracy=95.3] Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 5/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=1.89, accuracy=95.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6, Validation Accuracy: 95.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Epoch 5/6 [Train]:   0%|          | 0/40 [00:14<?, ?it/s, loss=0]\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:00<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:01<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:02<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:03<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:04<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:05<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:06<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:07<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:08<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:09<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:10<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:11<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:12<?, ?it/s, loss=0]\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\u001b[A\n",
      "Epoch 6/6 [Train]:   0%|          | 0/40 [00:13<?, ?it/s, loss=0]\u001b[A\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 5/6 [Validation]:   0%|          | 0/10 [00:14<?, ?it/s, loss=1.89, accuracy=95.5]\n",
      "\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0279, accuracy=100] \u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0323, accuracy=100]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0377, accuracy=100]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.0595, accuracy=100]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.186, accuracy=99]  \u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:00<?, ?it/s, loss=0.196, accuracy=99.1]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.774, accuracy=97.7]\u001b[A\u001b[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.779, accuracy=97.9]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/6 [Validation]:   0%|          | 0/10 [00:01<?, ?it/s, loss=0.917, accuracy=97.5]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6, Validation Accuracy: 97.45%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "#     for batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         token_type_ids = batch['token_type_ids'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         train_pbar.set_postfix({'loss': train_loss / (train_pbar.n + 1)})\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Validation]')\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             token_type_ids = batch['token_type_ids'].to(device)\n",
    "#             labels = batch['labels'].to(device)\n",
    "#             outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
    "#             val_loss += outputs.loss.item()\n",
    "#             _, predicted = torch.max(outputs.logits, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#             val_pbar.set_postfix({'loss': val_loss / (val_pbar.n + 1), 'accuracy': 100 * correct / total})\n",
    "\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ST_fG_jOHYG"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(model.state_dict(), 'aspect_sentiment_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "C9xkjK_APP8F"
   },
   "outputs": [],
   "source": [
    "def load_saved_model(model_path):\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "    model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUPqTL2uPTsB",
    "outputId": "8ab7cab6-5135-4b94-c273-19c915f00ab0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\heyfa\\AppData\\Local\\Temp\\ipykernel_10140\\3249253587.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_saved_model('./10/aspect_sentiment_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzGl5wdBTFtp",
    "outputId": "7cde34c1-7663-43ea-b385-a93c5728451c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import re\n",
    "\n",
    "def predict_sentiments(text, model, tokenizer, label_encoder, device):\n",
    "    aspects = ['battery', 'display', 'design', 'performance', 'camera']\n",
    "    results = {}\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for aspect in aspects:\n",
    "        # Check if the aspect is mentioned in the text\n",
    "        aspect_pattern = r'\\b' + re.escape(aspect) + r'\\b'\n",
    "        if re.search(aspect_pattern, text, re.IGNORECASE):\n",
    "            # Find the sentence containing the aspect\n",
    "            sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "            relevant_sentence = next((s for s in sentences if re.search(aspect_pattern, s, re.IGNORECASE)), text)\n",
    "\n",
    "            # Prepare input for the model\n",
    "            inputs = tokenizer.encode_plus(\n",
    "                aspect,\n",
    "                relevant_sentence,\n",
    "                add_special_tokens=True,\n",
    "                max_length=128,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            # Make prediction\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    inputs['input_ids'].to(device),\n",
    "                    attention_mask=inputs['attention_mask'].to(device),\n",
    "                    token_type_ids=inputs['token_type_ids'].to(device)\n",
    "                )\n",
    "\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            sentiment = label_encoder.inverse_transform([predicted.item()])[0]\n",
    "\n",
    "            results[aspect] = sentiment\n",
    "\n",
    "    return results\n",
    "\n",
    "# Assuming you have already initialized these:\n",
    "# model = BertForSequenceClassification.from_pretrained('path_to_your_saved_model')\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# label_encoder = LabelEncoder()  # This should be the same encoder used during training\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# predictions = predict_sentiments(text, model, tokenizer, label_encoder, device)\n",
    "\n",
    "# for aspect, sentiment in predictions.items():\n",
    "#     print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: battery, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = \"battery doesn't last long\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: battery, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = \"battery short life\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: design, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = \"design is very old\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: design, Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "text = \"design is latest technology\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: battery, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = \"battery is drains very fast with short battery life\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: camera, Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "text = \"picture from rear camera is crystal clear\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: camera, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = \"picture from rear camera is blur\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: battery, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = \"it becomes too too too hot ,iam so disappointed with this brand . there is no difference between 4g and 5g . battery was weak iam charging twice a day,for basic level of usage itself.\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: battery, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = \"having big one major problem it's very fast battery draining\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: battery, Sentiment: positive\n",
      "Aspect: display, Sentiment: positive\n",
      "Aspect: design, Sentiment: positive\n",
      "Aspect: performance, Sentiment: positive\n",
      "Aspect: camera, Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "text = '''Realme p1 5g is the one of the best smart phone under 15k.. camera it's ok\n",
    "Battery  maximum 1days\n",
    "Display is amoled so nice \n",
    "Design very nice\n",
    "Performance.. mediatek 7050 is very powerful.. free fire 60fps....and...Bgmi.. smooth extreme.... I Love  this phone..'''\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlOb-2g_Uiqo",
    "outputId": "2cd6c270-8bf5-4dc5-b00a-c9b22b2e67ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: battery, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "But battery backup very poor\n",
    "Atleast one day not stand by battery backup\n",
    "Very fast drain the battery\n",
    "Worst battery\n",
    "Not go to buy this phone'''\n",
    "\n",
    "predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "for aspect, sentiment in predictions.items():\n",
    "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Design - Awesome Looking and\n",
      "Sentence 2: Dimensity 7050 5 G Processor - Good   Amoled Display - Decent\n",
      "Sentence 3: Sound Experience is also Good but\n",
      "Sentence 4: Camera Quality is superb\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def split_text(text):\n",
    "    # First, split by newline characters\n",
    "    split_by_newlines = text.split('\\n')\n",
    "    all_sentences = []\n",
    "    \n",
    "    for part in split_by_newlines:\n",
    "        if part.strip():  # Ignore empty parts\n",
    "            all_sentences.extend(split_on_conjunctions(part))\n",
    "    \n",
    "    return all_sentences\n",
    "\n",
    "def split_on_conjunctions(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    for token in doc:\n",
    "        current_sentence.append(token.text)\n",
    "        \n",
    "        # If we encounter a coordinating conjunction or new sentence, split\n",
    "        if token.dep_ == 'cc' or token.text == '.':\n",
    "            sentences.append(' '.join(current_sentence).strip())\n",
    "            current_sentence = []\n",
    "    \n",
    "    # Add the final sentence if any\n",
    "    if current_sentence:\n",
    "        sentences.append(' '.join(current_sentence).strip())\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Test case\n",
    "text = '''Design - Awesome Looking and Dimensity 7050 5G Processor - Good  Amoled Display - Decent\n",
    "Sound Experience is also Good but Camera Quality is superb'''\n",
    "\n",
    "sentences = split_text(text)\n",
    "\n",
    "# Output each split sentence\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {idx+1}: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences(text):\n",
    "#     text = preprocess_text(text)\n",
    "    \n",
    "    sentences = split_text(text)\n",
    "    \n",
    "    rating =3\n",
    "    c=0\n",
    "    \n",
    "    for text in sentences :\n",
    "        \n",
    "        print(text)\n",
    "        print()\n",
    "        \n",
    "        predictions = predict_sentiments(text, loaded_model, tokenizer, label_encoder, device='cpu')\n",
    "\n",
    "        for aspect, sentiment in predictions.items():\n",
    "            print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")\n",
    "            \n",
    "            if sentiment == 'positive':\n",
    "                rating +=1\n",
    "            elif sentiment == 'negative':\n",
    "                rating -=1\n",
    "            else:\n",
    "                rating +=0.5\n",
    "                \n",
    "            c+=1\n",
    "    print('Rating : ', rating+(5-c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "design   awesome looking\n",
      "dimensity       g processor   good\n",
      "amoled display   decent\n",
      "sound experience is also good\n",
      "camera quality   superb\n",
      "smoothly running all apps \n",
      "design awesome looking dimensity g processor good amoled display decent sound experience also good camera quality superb smoothly running apps\n",
      "\n",
      "Aspect: display, Sentiment: positive\n",
      "Aspect: design, Sentiment: positive\n",
      "Aspect: camera, Sentiment: positive\n",
      "Rating :  5\n"
     ]
    }
   ],
   "source": [
    "text = '''Design - Awesome Looking\n",
    "Dimensity 7050 5G Processor - Good\n",
    "Amoled Display - Decent\n",
    "Sound Experience is also Good\n",
    "Camera Quality - superB\n",
    "Smoothly Running All Apps.'''\n",
    "predict_sentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it becomes too too too hot  iam so disappointed with this brand   there is no difference between  g and  g   battery was weak iam charging twice a day for basic level of usage itself \n",
      "becomes hot iam disappointed brand no difference g g battery weak iam charging twice day basic level usage\n",
      "\n",
      "Aspect: battery, Sentiment: negative\n",
      "Rating :  3\n"
     ]
    }
   ],
   "source": [
    "text = '''it becomes too too too hot ,iam so disappointed with this brand . there is no difference between 4g and 5g . battery was weak iam charging twice a day,for basic level of usage itself.'''\n",
    "predict_sentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''SERIOUSLY IT'S TOO GOOD.\n",
    "GAME IS SMOOTH IN BGMI BASIS NO.NO.NO..IT'S OVER SMOOTH.\n",
    "YOU FEEL ALWAYS COOL YOUR PHONE..CAMERA QUALITY..OHO.OHO.OHO..NICE'''\n",
    "predict_sentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice phone this price range\n",
      "\n",
      "Camera quality is not that good\n",
      "\n",
      "Aspect: camera, Sentiment: negative\n",
      "Very bad display\n",
      "\n",
      "Aspect: display, Sentiment: negative\n",
      "Battery back poor\n",
      "\n",
      "Aspect: battery, Sentiment: negative\n",
      "Rating :  2\n"
     ]
    }
   ],
   "source": [
    "text = '''Nice phone this price range\n",
    "Camera quality is not that good\n",
    "Very bad display\n",
    "Battery back poor'''\n",
    "predict_sentences(text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
